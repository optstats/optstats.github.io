<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>An Introduction to Optimizaiton - optstats</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta itemprop="name" content="An Introduction to Optimizaiton">
<meta itemprop="description" content="The screening of book An Introduction to Optimization."><meta itemprop="datePublished" content="2022-09-23T03:16:58+05:30" />
<meta itemprop="dateModified" content="2022-09-23T03:16:58+05:30" />
<meta itemprop="wordCount" content="424">
<meta itemprop="keywords" content="An Introduction to Optimization," /><meta property="og:title" content="An Introduction to Optimizaiton" />
<meta property="og:description" content="The screening of book An Introduction to Optimization." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://optstats.github.io/2022/09/an-introduction-to-optimizaiton/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-23T03:16:58+05:30" />
<meta property="article:modified_time" content="2022-09-23T03:16:58+05:30" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="An Introduction to Optimizaiton"/>
<meta name="twitter:description" content="The screening of book An Introduction to Optimization."/>
<link rel="stylesheet" type="text/css" media="screen" href="https://optstats.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://optstats.github.io/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://optstats.github.io/css/dark.css" />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
		<script src="https://optstats.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	
		<div class="avatar">
			<a href="https://optstats.github.io/">
				<img src="/icon.jpeg" alt="optstats" />
			</a>
		</div>
	
	<h1 class="site-title"><a href="https://optstats.github.io/">optstats</a></h1>
	<div class="site-description"><p>Notebooks</p><nav class="nav social">
			<ul class="flat"><li><a href="https://github.com/optstats" title="Github"><i data-feather="github"></i></a></li></ul>
		</nav>
		
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/posts">All posts</a>
			</li>
			
			<li>
				<a href="/about">About</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


    
<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css"
    integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5"
    crossorigin="anonymous">

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js"
    integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd"
    crossorigin="anonymous"></script>

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
            ],
            throwOnError : false
        });
    });
</script>






		<div class="post">
			<div class="post-header">
				
					<div class="meta">
						<div class="date">
							<span class="day">23</span>
							<span class="rest">Sep 2022</span>
						</div>
					</div>
				
				<div class="matter">
					<h1 class="title">An Introduction to Optimizaiton</h1>
				</div>
			</div>

			
			
			<aside class="toc">
				<header>
				<h2>Contents</h2>
				</header>
				<nav id="TableOfContents">
  <ol>
    <li><a href="#chapter-6-basics-of-set-constrained-and-unconstrained-optimizaiton">Chapter 6. Basics of Set-Constrained and Unconstrained Optimizaiton</a>
      <ol>
        <li><a href="#61-introduction">6.1 Introduction</a></li>
        <li><a href="#62-condition-for-local-minimizers">6.2 Condition for Local Minimizers</a></li>
      </ol>
    </li>
    <li><a href="#chapter-7-one-dimensional-search-methods">Chapter 7. One Dimensional Search Methods</a>
      <ol>
        <li><a href="#71-introduction">7.1 Introduction</a></li>
        <li><a href="#74-bisection-method">7.4 Bisection Method</a></li>
        <li><a href="#75-newtons-method">7.5 Newton&rsquo;s Method</a></li>
      </ol>
    </li>
  </ol>
</nav>
			</aside>
			
					
			<div class="markdown">
				<h2 id="chapter-6-basics-of-set-constrained-and-unconstrained-optimizaiton">Chapter 6. Basics of Set-Constrained and Unconstrained Optimizaiton</h2>
<h3 id="61-introduction">6.1 Introduction</h3>
<ol>
<li>
<p>objective function/cost function</p>
</li>
<li>
<p>decision variables</p>
</li>
<li>
<p>constraint set/feasiable set</p>
</li>
<li>
<p>extremizers</p>
<ul>
<li>minimizer</li>
<li>maximizer</li>
</ul>
</li>
<li>
<p>constrained optimization problem</p>
</li>
<li>
<p>unconstrained opitmization problem: $\Omega=R^n$</p>
</li>
<li>
<p>minimizer</p>
<ul>
<li>local minimizer
<ul>
<li>What we often to find</li>
<li>multiple</li>
</ul>
</li>
<li>global minimizer
<ul>
<li>It is difficult to find.</li>
</ul>
</li>
<li>strict</li>
</ul>
</li>
</ol>
<h3 id="62-condition-for-local-minimizers">6.2 Condition for Local Minimizers</h3>
<ol>
<li>
<p>gradient and Hessian</p>
</li>
<li>
<p>feasiable direction</p>
<ul>
<li>Why: a minimizer may be lie either in the interior or on the boundary of $\Omega$. To study the minimizer lie on the boundary.</li>
<li>definiton: $d\in R^n, d\neq 0$, a feasible direction at $x \in\Omega$ if there is $t&gt;0$ such that $x+\alpha d\in \Omega$ for all $\alpha\in [0,t]$.</li>
<li>directional derivative $\frac{\partial f}{\partial d}$
<ul>
<li>how to understand the directional derivative</li>
<li>the relation between the directional derivative and gradient</li>
<li>what if the $||d||=1$ and how to relate the increase rate of gradient on specified direction</li>
</ul>
</li>
</ul>
</li>
<li>
<p>first-order necessary condition</p>
<ul>
<li>if $x^\ast$ is a local minimizer, for any feasiable direction $d$ at $x^\ast$, we have $d^T\nabla f(x^\ast)\geq 0$</li>
<li>the interior case: $\nabla f(x^\ast)=0$</li>
</ul>
</li>
<li>
<p>second-order necessary condition</p>
<ul>
<li>for a local minimizer $x^\ast$ and the feasiable direction $d$ of $x\ast$, if the $d^T\nabla f(x^\ast)=0$, then $d^TH(x^\ast)d\geq 0$, where the $H$ is the Hessian of $f$.</li>
<li>the interior case: $\nabla f(x^\ast)=0$ and for all $d\in R^n$, we have $d^TH(x^\ast)d\geq 0$</li>
</ul>
</li>
<li>
<p>second-order sufficient condition, interior case</p>
<ul>
<li>if $\nabla f(x^\ast)=0$ and $H(x^\ast)&gt; 0$ then we say $x^\ast$ is a strict minimizer of $f$.</li>
</ul>
</li>
</ol>
<h2 id="chapter-7-one-dimensional-search-methods">Chapter 7. One Dimensional Search Methods</h2>
<h3 id="71-introduction">7.1 Introduction</h3>
<ol>
<li>
<p>We focus on the one dim problem, that is $f:R\rightarrow R$.</p>
</li>
<li>
<p>iterative search algorithm (linear search method)</p>
<ul>
<li>a sequence of $x_i,i\in[1,k]$</li>
<li>$x_{i+1}$ depends on $x_i$ and $f$ or its derivative information</li>
</ul>
</li>
</ol>
<h3 id="74-bisection-method">7.4 Bisection Method</h3>
<ol>
<li>To use the midpoint of interval to reduce the uncertainty of interval</li>
<li>Let f is unimodal and continuous differentiate on interval $[a,b]$, if the derivative of midpoint $x_0$, $f'(x_0)&lt;0$, then we move to the interval $[x_0,b]$ to find the minimizer, otherwise, we move to the interval $[a,x_0]$ to fnd the minimizer. Namely, if $f'(x_0)&lt;0$, we deduce that the minimizer lies to the left of $x_0$ and vice-versa.</li>
<li>We repeat the process iteratively until end with finding the $f'(x_0)=0$ where we set the final $x_0$ as a minimizer.</li>
<li>In each step, the interval is reduced by a factor of $\frac{1}{2}$.</li>
</ol>
<h3 id="75-newtons-method">7.5 Newton&rsquo;s Method</h3>
<ol>
<li>Assume at $x^{k}$, we can determine $f(x^{k})$, $f'(x^k)$, $f''(x^k)$, then we utilize the second-order expansion at $x^k$, namely a quadratic function to approximate the function value at any point of $f(x)$. Therefore, we have $f(x)=f(x^k)+f'(x^k)(x-x^k)+\frac{1}{2}f''(x^k)(x-x^k)^2$. To minimize $f$, for the first-order necessary condition, we have $f'(x)=0=f'(x^k)+f''(x^k)(x-x^k)$. Setting $x=x^{k+1}$, we obtain</li>
</ol>
<p>$$x^{k+1}=x^k-\frac{f'(x^k)}{f''(x^k)}$$</p>

			</div>

			<div class="tags">
				
					
						<ul class="flat">
							
							<li class="tag-li"><a href="/tags/an-introduction-to-optimization">An Introduction to Optimization</a></li>
							
						</ul>
					
				
			</div>

			
			
			<div class="back">
				<a href="https://optstats.github.io/"><span aria-hidden="true">← Back</span></a>
			</div>
			

			<div class="back">
				
			</div><div id="disqus_thread"></div>
<script type="text/javascript">
	(function () {
		
		
		if (window.location.hostname == "localhost")
			return;

		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		var disqus_shortname = 'optstats-github-io';
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>Please enable JavaScript to view the </a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
		
	</div>
	
	<div class="footer wrapper">
	<nav class="nav">
		<div>2022  ©Copyright Hugo </div>
		
	</nav>
</div><script>feather.replace()</script>
</body>
</html>
